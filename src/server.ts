/**
 * NotebookLM MCP Server
 * 
 * Supports both Stdio and HTTP transports.
 * - Stdio: For programmatic clients or legacy integrations
 * - HTTP: For Claude Desktop via Connectors (use cloudflared tunnel)
 * 
 * Usage:
 *   Stdio mode:  node dist/server.js --stdio
 *   HTTP mode:   node dist/server.js (default, uses port 3001)
 * 
 * For Claude Desktop with MCP Apps UI:
 *   1. Run: node dist/server.js
 *   2. Run: npx cloudflared tunnel --url http://localhost:3001
 *   3. Add the generated URL as a Custom Connector in Claude Settings > Connectors
 */

import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { SSEServerTransport } from "@modelcontextprotocol/sdk/server/sse.js";
import { StreamableHTTPServerTransport } from "@modelcontextprotocol/sdk/server/streamableHttp.js";
import { isInitializeRequest } from "@modelcontextprotocol/sdk/types.js";
import {
    registerAppTool,
    registerAppResource,
    RESOURCE_MIME_TYPE,
} from "@modelcontextprotocol/ext-apps/server";
import cors from "cors";
import express from "express";
import fs from "node:fs/promises";
import * as fsSync from "node:fs";
import path from "node:path";
import { fileURLToPath } from 'url';
import { z } from "zod";
import { NotebookLMClient } from "./notebooklm_client.js";
import sharp from "sharp";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// --- CONFIGURATION ---
const LOG_FILE = path.join(path.dirname(fileURLToPath(import.meta.url)), '../server.log');
const HTTP_PORT = Number(process.env.PORT) || 3001;

// --- State Management ---
interface ActiveNotebook {
    notebookId: string;
    url: string;
    title?: string;
    lastUsedAt: number;
    sourceIds?: string[];
}

let activeNotebooks: ActiveNotebook[] = [];

function setActiveNotebook(url: string, notebookId: string, title?: string, sourceIds?: string[]) {
    // Remove if exists to re-add at top
    activeNotebooks = activeNotebooks.filter(n => n.url !== url);

    activeNotebooks.unshift({
        notebookId,
        url,
        title,
        lastUsedAt: Date.now(),
        sourceIds
    });

    // Keep last 5
    if (activeNotebooks.length > 5) activeNotebooks.pop();
    logToFile(`[Session] Active notebook set: ${url} (${notebookId})`);
}

function getActiveNotebook(): ActiveNotebook | null {
    return activeNotebooks.length > 0 ? activeNotebooks[0] : null;
}

// --- Async Job Queue for Infographic Generation ---
interface InfographicJob {
    id: string;
    videoUrl: string;
    status: 'pending' | 'processing' | 'completed' | 'failed';
    imageUrl?: string;
    viewerUrl?: string;
    imageData?: string; // base64
    error?: string;
    createdAt: number;
    completedAt?: number;
}

const infographicJobs = new Map<string, InfographicJob>();

// --- Per-User Re-Auth (SSE Push) ---
// Connected extension SSE clients, keyed by user token
import { Response as ExpressResponse } from 'express';
const reauthSseClients = new Map<string, Set<ExpressResponse>>();
const needsReauth = new Map<string, boolean>();

function pushReauthEvent(userToken: string) {
    const key = userToken || '__legacy__';
    needsReauth.set(key, true);
    const clients = reauthSseClients.get(key);
    if (clients && clients.size > 0) {
        const event = `data: ${JSON.stringify({ type: 'reauth', user_token: key })}\n\n`;
        for (const res of clients) {
            try { res.write(event); } catch (e) { /* client disconnected */ }
        }
        logToFile(`[SSE] Pushed reauth event to ${clients.size} client(s) for ${key}`);
    } else {
        logToFile(`[SSE] No connected extensions for ${key}. User must manually re-sync.`);
    }
}

function generateJobId(): string {
    return `job_${Date.now()}_${Math.random().toString(36).substring(2, 8)}`;
}

// Cleanup old jobs (older than 10 minutes)
function cleanupOldJobs() {
    const TEN_MINUTES = 10 * 60 * 1000;
    const now = Date.now();
    for (const [id, job] of infographicJobs.entries()) {
        if (now - job.createdAt > TEN_MINUTES) {
            infographicJobs.delete(id);
            logToFile(`[Jobs] Cleaned up old job: ${id}`);
        }
    }
}

// --- DEBUG LOGGING ---
function logToFile(msg: string) {
    const timestamp = new Date().toLocaleString();
    try {
        fsSync.appendFileSync(LOG_FILE, `[${timestamp}] ${msg}\n`);
    } catch { }
    console.error(`[${timestamp}] ${msg}`);
}

// --- Cookie Storage (from Chrome Extension) ---
import { NativeFetchClient } from "./native_fetch_client.js";

interface ChromeCookie {
    name: string;
    value: string;
    domain: string;
    path: string;
    secure: boolean;
    httpOnly: boolean;
    expirationDate?: number;
}

const USER_DATA_DIR = path.join(path.dirname(fileURLToPath(import.meta.url)), '../user_data');
const COOKIES_FILE = path.join(USER_DATA_DIR, 'user_cookies.json');

// Per-user cookie storage
interface UserCookieData {
    cookies: ChromeCookie[];
    receivedAt: number;
    userAgent?: string;
}
const userCookies: Map<string, UserCookieData> = new Map();

// Legacy single-user mode (for backwards compatibility)
let legacyCookies: ChromeCookie[] = [];
let legacyCookiesReceivedAt: number | null = null;
let legacyCookiesUserAgent: string | undefined = undefined;

function generateUserToken(): string {
    return 'user_' + Math.random().toString(36).substring(2, 10) + Date.now().toString(36);
}

function persistAllCookies() {
    try {
        if (!fsSync.existsSync(USER_DATA_DIR)) {
            fsSync.mkdirSync(USER_DATA_DIR, { recursive: true });
        }
        const data: Record<string, UserCookieData> = {};
        userCookies.forEach((value, key) => {
            data[key] = value;
        });
        // Also save legacy cookies under special key
        if (legacyCookies.length > 0 && legacyCookiesReceivedAt) {
            data['__legacy__'] = { cookies: legacyCookies, receivedAt: legacyCookiesReceivedAt, userAgent: legacyCookiesUserAgent };
        }
        fsSync.writeFileSync(COOKIES_FILE, JSON.stringify(data, null, 2));
        logToFile(`[Cookies] Saved cookies for ${userCookies.size} users to disk.`);
    } catch (e: any) {
        logToFile(`[Cookies] Failed to save cookies: ${e.message}`);
    }
}

function loadAllCookies() {
    try {
        if (fsSync.existsSync(COOKIES_FILE)) {
            const data = JSON.parse(fsSync.readFileSync(COOKIES_FILE, 'utf-8'));
            for (const [key, value] of Object.entries(data)) {
                const userData = value as UserCookieData;
                if (key === '__legacy__') {
                    legacyCookies = userData.cookies;
                    legacyCookiesReceivedAt = userData.receivedAt;
                    legacyCookiesUserAgent = userData.userAgent;
                } else if (Array.isArray(userData.cookies) && typeof userData.receivedAt === 'number') {
                    userCookies.set(key, userData);
                }
            }
            logToFile(`[Cookies] Loaded cookies for ${userCookies.size} users from disk.`);
        }
    } catch (e: any) {
        logToFile(`[Cookies] Failed to load cookies: ${e.message}`);
    }
}

// Load on startup
loadAllCookies();

export function setCookiesFromExtension(cookies: ChromeCookie[], userToken?: string, userAgent?: string) {
    if (userToken) {
        userCookies.set(userToken, { cookies, receivedAt: Date.now(), userAgent });
        logToFile(`[Cookies] Received ${cookies.length} cookies for user ${userToken}`);
    } else {
        // Legacy mode
        legacyCookies = cookies;
        legacyCookiesReceivedAt = Date.now();
        legacyCookiesUserAgent = userAgent;
        logToFile(`[Cookies] Received ${cookies.length} cookies (legacy mode)`);
    }
    persistAllCookies();
}

export function getCookiesForUser(userToken?: string): { cookies: ChromeCookie[], fresh: boolean, userAgent?: string } {
    const MAX_AGE = 60 * 60 * 1000; // 60 minutes

    if (userToken && userCookies.has(userToken)) {
        const data = userCookies.get(userToken)!;
        const fresh = (Date.now() - data.receivedAt) < MAX_AGE;
        return { cookies: data.cookies, fresh, userAgent: data.userAgent };
    }

    // Fallback to legacy
    if (legacyCookies.length > 0 && legacyCookiesReceivedAt) {
        const fresh = (Date.now() - legacyCookiesReceivedAt) < MAX_AGE;
        return { cookies: legacyCookies, fresh, userAgent: legacyCookiesUserAgent };
    }

    return { cookies: [], fresh: false };
}

export function hasFreshCookies(userToken?: string): boolean {
    const { cookies, fresh } = getCookiesForUser(userToken);
    return cookies.length > 0 && fresh;
}

export function isValidUserToken(token: string): boolean {
    return userCookies.has(token);
}

export { generateUserToken };

// --- Per-User Client Management ---
const userClients: Map<string, { client: NativeFetchClient | NotebookLMClient, isNative: boolean }> = new Map();

async function getClient(userToken?: string): Promise<NotebookLMClient | NativeFetchClient> {
    const clientKey = userToken || '__legacy__';
    const { cookies, fresh, userAgent } = getCookiesForUser(userToken);

    // If we have fresh cookies for this user, prefer NativeFetchClient
    if (fresh && cookies.length > 0) {
        const existing = userClients.get(clientKey);
        if (!existing || !existing.isNative) {
            logToFile(`[Client] üöÄ Using NativeFetchClient for ${userToken || 'legacy user'}`);
            // Close old Playwright client if exists
            if (existing && !existing.isNative) {
                try { await (existing.client as NotebookLMClient).stop(); } catch { }
            }
            const client = new NativeFetchClient(cookies, userAgent);
            await client.start();
            userClients.set(clientKey, { client, isNative: true });
        }
        return userClients.get(clientKey)!.client;
    }

    // Fallback to Playwright client (shared singleton for legacy mode)
    const existing = userClients.get(clientKey);
    if (!existing || existing.isNative) {
        logToFile(`[Client] üé≠ Falling back to Playwright NotebookLMClient for ${userToken || 'legacy user'}`);
        const headlessEnv = process.env.NOTEBOOKLM_HEADLESS;
        const headless = headlessEnv === undefined ? true : headlessEnv === "true";
        const client = new NotebookLMClient(headless);
        await client.start();
        userClients.set(clientKey, { client, isNative: false });
        logToFile("NotebookLMClient started successfully.");
    }
    return userClients.get(clientKey)!.client;
}

// --- Resource URI ---
const resourceUri = "ui://infographic/view.html";

// --- Tool & Resource Registration ---
// --- Tool & Resource Registration ---
function registerTools(server: McpServer) {
    // Register AppResource (serves bundled HTML for MCP App UI)
    registerAppResource(
        server,
        resourceUri,
        resourceUri,
        { mimeType: RESOURCE_MIME_TYPE },
        async () => {
            logToFile(`[MCP] Resource requested: ${resourceUri}`);
            try {
                const htmlPath = path.join(__dirname, "../dist/src/mcp-app.html");
                logToFile(`[MCP] Serving UI from: ${htmlPath}`);
                const html = await fs.readFile(htmlPath, "utf-8");
                return {
                    contents: [
                        { uri: resourceUri, mimeType: RESOURCE_MIME_TYPE, text: html },
                    ],
                };
            } catch (e) {
                logToFile(`Failed to read mcp-app.html: ${e}`);
                throw e;
            }
        }
    );

    // --- Helper for wrapping errors ---
    const wrapError = (msg: string) => ({ content: [{ type: "text" as const, text: msg }], isError: true });

    // --- Tool: ping (Debug) ---
    server.tool(
        "ping",
        "A simple ping tool to verify tool discovery works.",
        { message: z.string().optional() },
        async ({ message }) => {
            return {
                content: [{ type: "text", text: `Pong! You said: ${message || "nothing"}` }]
            };
        }
    );

    // --- Tool: generate_summary (Standard MCP) ---
    logToFile("Registering tool: generate_summary");
    server.tool(
        "generate_summary",
        "Generates a comprehensive summary of a YouTube video or NotebookLM notebook content. Side-effect: Sets this as the active notebook.",
        {
            url: z.string().url().describe("The URL of the YouTube video OR a direct NotebookLM link. Optional if an active notebook exists in the session."),
            user_token: z.string().optional().describe("Optional user token for multi-user mode. Get this from the /register.html page and configure your extension with it.")
        },
        async (args) => {
            const targetUrl = args.url;
            const userToken = args.user_token;
            logToFile(`[MCP] Request: Summary for ${targetUrl} (user: ${userToken || 'legacy'})`);
            let notebookId: string = "unknown";
            try {
                const client = await getClient(userToken);

                // Race the summary against a 40s timeout to beat Cloudflare's ~60s limit
                const SUMMARY_TIMEOUT = 40000;
                const summaryPromise = client.generateSummary(targetUrl);
                const timeoutPromise = new Promise<null>((resolve) => setTimeout(() => resolve(null), SUMMARY_TIMEOUT));
                const summary = await Promise.race([summaryPromise, timeoutPromise]);

                // Update Session State
                notebookId = client._parseNotebookUrl(targetUrl) || "unknown";
                setActiveNotebook(targetUrl, notebookId);

                if (summary === null) {
                    logToFile(`[MCP] Summary timed out after ${SUMMARY_TIMEOUT / 1000}s for ${targetUrl}`);
                    return {
                        content: [{ type: "text", text: `‚è≥ **Summary is taking longer than expected.**\n\nThe notebook is loaded and processing. Please try asking again in a moment ‚Äî it should be much faster on retry since the notebook is now cached.` }],
                    };
                }

                return {
                    content: [{ type: "text", text: `üìù **Summary Generated**\n\n${summary}` }],
                    meta: { source: targetUrl, notebookId }
                };
            } catch (e: any) {
                // AUTH FAILURE HANDLER
                if (e.message.includes("Authentication required")) {
                    const reauthKey = userToken || '__legacy__';
                    pushReauthEvent(reauthKey);
                    logToFile(`[MCP] ‚ö†Ô∏è Summary auth failed. Pushed reauth event for ${reauthKey}.`);
                    return {
                        content: [{ type: "text", text: `üîê **Authentication needed.** Your browser extension should prompt you to log in. Please try again after logging in.` }],
                        isError: true
                    };
                }
                logToFile(`Error: ${e.message}`);
                return { content: [{ type: "text", text: `Error generating summary: ${e.message}` }], isError: true };
            }
        }
    );

    // --- Tool: get_active_notebook ---
    logToFile("Registering tool: get_active_notebook");
    server.tool(
        "get_active_notebook",
        "Returns the most recently used notebook in this session. Use this to resolve references like 'that notebook' or 'it'.",
        {},
        async () => {
            const nb = getActiveNotebook();
            return {
                content: [{ type: "text" as const, text: JSON.stringify(nb, null, 2) }],
                meta: { activeNotebook: nb }
            };
        }
    );

    // --- Tool: list_sources (MCP App Enabled) ---
    logToFile("Registering tool: list_sources");
    registerAppTool(
        server,
        "list_sources",
        {
            title: "List Sources",
            description: "Lists all sources in a NotebookLM notebook. Returns source IDs, titles, types, and original URLs. Side-effect: Sets this as the active notebook.",
            inputSchema: z.object({
                url: z.string().url().describe("The URL of the NotebookLM notebook."),
                user_token: z.string().optional().describe("Optional user token for multi-user mode.")
            }) as any,
            _meta: { ui: { resourceUri } },
        },
        async (args: any) => {
            const url = args.url;
            const userToken = args.user_token;
            logToFile(`[MCP] Request: List Sources for ${url} (user: ${userToken || 'legacy'})`);
            try {
                const client = await getClient(userToken);
                const sources = await client.listSources(url);

                // Update Session State
                const notebookId = client._parseNotebookUrl(url) || "unknown";
                setActiveNotebook(url, notebookId, undefined, sources.map(s => s.sourceId));

                // Format as markdown list for UI
                const sourceList = sources.map(s => `- **${s.title}** (${s.type})\n  Link: [Open](${s.originalUrl || '#'}) | ID: \`${s.sourceId}\``).join('\n\n');

                return {
                    content: [{ type: "text" as const, text: `üìö **Notebook Sources**\n\n${sourceList}` }],
                    meta: { count: sources.length, sources }
                };
            } catch (e: any) {
                return wrapError(`Error listing sources: ${e.message}`);
            }
        }
    );

    // --- Tool: ask_question (MCP App Enabled) ---
    logToFile("Registering tool: ask_question");
    registerAppTool(
        server,
        "ask_question",
        {
            title: "Ask Question",
            description: "Asks a question about the active video/notebook. USE THIS TOOL for any follow-up questions about the content, even if no URL is provided (it will use the active session). Do not answer from general knowledge if the user is asking about the video's topic.",
            inputSchema: z.object({
                url: z.string().url().optional().describe("The URL of the YouTube video OR a direct NotebookLM link. Optional if an active notebook exists in the session."),
                question: z.string().describe("The question to ask"),
                source_id: z.string().optional().describe("Optional: The specific Source ID to target (if known from list_sources)."),
                user_token: z.string().optional().describe("Optional user token for multi-user mode.")
            }) as any,
            _meta: { ui: { resourceUri } },
        },
        async (args: any) => {
            const targetUrl = args.url;
            const question = args.question;
            const source_id = args.source_id;
            const userToken = args.user_token;

            logToFile(`[MCP] Request: Question for ${targetUrl}: "${question}" (user: ${userToken || 'legacy'})`);
            try {
                const client = await getClient(userToken);

                // Race against 40s timeout to beat Cloudflare's ~60s limit
                const QUERY_TIMEOUT = 40000;
                const queryPromise = client.query(targetUrl!, question, source_id);
                const timeoutPromise = new Promise<null>((resolve) => setTimeout(() => resolve(null), QUERY_TIMEOUT));
                const answer = await Promise.race([queryPromise, timeoutPromise]);

                // Update Session State
                const notebookId = client._parseNotebookUrl(targetUrl!) || "unknown";
                setActiveNotebook(targetUrl!, notebookId);

                if (answer === null) {
                    logToFile(`[MCP] Question timed out after ${QUERY_TIMEOUT / 1000}s`);
                    return {
                        content: [{ type: "text" as const, text: `‚è≥ **Taking longer than expected.** The notebook is loaded. Please ask your question again ‚Äî it should work on retry.` }],
                    };
                }

                return {
                    content: [{ type: "text" as const, text: `‚ùì **Question:** ${question}\n\nüí° **Answer:**\n${answer}` }],
                    meta: { sourceId: source_id || "auto", source: targetUrl, notebookId }
                };
            } catch (e: any) {
                if (e.message.includes("Authentication required")) {
                    const reauthKey = userToken || '__legacy__';
                    pushReauthEvent(reauthKey);
                    logToFile(`[MCP] ‚ö†Ô∏è Question auth failed. Pushed reauth event for ${reauthKey}.`);
                    return {
                        content: [{ type: "text" as const, text: `üîê **Authentication needed.** Your browser extension should prompt you to log in. Please try again after logging in.` }],
                        isError: true
                    };
                }
                logToFile(`Error: ${e.message}`);
                return wrapError(`Error asking question: ${e.message}`);
            }
        }
    );

    // --- Tool: generate_infographic (ASYNC - Returns job ID immediately) ---
    logToFile("Registering tool: generate_infographic");
    server.tool(
        "generate_infographic",
        "Starts generating a visual infographic for a YouTube video (async). Returns a job_id immediately. Use 'check_infographic_status' with the job_id to get the result when ready. Generation typically takes 1-3 minutes.",
        {
            video_url: z.string().describe("The URL of the YouTube video"),
            user_token: z.string().optional().describe("Optional user token for multi-user mode.")
        },
        async (args) => {
            const video_url = args.video_url;
            const userToken = args.user_token;
            logToFile(`[MCP] Request: Infographic for ${video_url} (user: ${userToken || 'legacy'})`);

            // Cleanup old jobs
            cleanupOldJobs();

            // --- Deduplication: Reuse in-flight job for same video + user ---
            const userKey = userToken || '__legacy__';
            let job: InfographicJob | undefined;
            let jobId: string = '';
            for (const [existingId, existingJob] of infographicJobs) {
                if (
                    existingJob.videoUrl === video_url &&
                    (existingJob.status === 'pending' || existingJob.status === 'processing') &&
                    (Date.now() - existingJob.createdAt) < 300000 // Only reuse if less than 5 min old
                ) {
                    job = existingJob;
                    jobId = existingId;
                    logToFile(`[Jobs] ‚ôªÔ∏è Reusing existing in-flight job ${jobId} for ${video_url} (dedup)`);
                    break;
                }
            }

            if (!job) {
                // Create new job
                jobId = generateJobId();
                job = {
                    id: jobId,
                    videoUrl: video_url,
                    status: 'pending',
                    createdAt: Date.now()
                };
                infographicJobs.set(jobId, job);
                logToFile(`[Jobs] Created job ${jobId} for ${video_url}`);

                // Start async processing (don't await!)
                (async () => {
                    try {
                        job.status = 'processing';
                        logToFile(`[Jobs] Processing job ${jobId}...`);

                        // Note: getClient handles choosing correct cookies based on userToken
                        const client = await getClient(userToken);

                        // Ensure browser is healthy before operations
                        await client.ensureBrowserReady();

                        const imageUrl = await client.generateInfographic(video_url);
                        logToFile(`[Jobs] Job ${jobId} got image URL: ${imageUrl}`);

                        // Store image info but don't mark complete yet
                        job.imageUrl = imageUrl;
                        job.viewerUrl = `http://localhost:${HTTP_PORT}/view?url=${encodeURIComponent(imageUrl)}`;

                        // Download and embed image BEFORE marking complete
                        try {
                            const imageBytes = await client.downloadResource(imageUrl);
                            const processedBuffer = await sharp(imageBytes, { failOnError: false })
                                .resize({ width: 1024, withoutEnlargement: true })
                                .jpeg({ quality: 85 })
                                .toBuffer();
                            job.imageData = processedBuffer.toString('base64');
                            logToFile(`[Jobs] Image downloaded for ${jobId} (${job.imageData.length} chars)`);
                        } catch (err: any) {
                            logToFile(`[Jobs] Image download failed for ${jobId}: ${err.message}`);
                        }

                        // NOW mark as completed (after image is ready)
                        job.status = 'completed';
                        job.completedAt = Date.now();
                        logToFile(`[Jobs] Job ${jobId} completed, hasImageData: ${!!job.imageData}`);
                    } catch (e: any) {
                        if (e.message.includes("Authentication required")) {
                            // ---- FLAG FOR EXTENSION RE-AUTH ----
                            const reauthKey = userToken || '__legacy__';
                            pushReauthEvent(reauthKey);
                            logToFile(`[Jobs] ‚ö†Ô∏è Auth failed for job ${jobId}. Pushed reauth event for ${reauthKey}. Waiting for extension to re-sync cookies...`);

                            // Wait up to 120s for the extension to re-sync fresh cookies
                            const REAUTH_TIMEOUT = 120000;
                            const REAUTH_POLL = 3000;
                            const reauthStart = Date.now();
                            let reauthSucceeded = false;

                            while (Date.now() - reauthStart < REAUTH_TIMEOUT) {
                                await new Promise(resolve => setTimeout(resolve, REAUTH_POLL));
                                if (!needsReauth.get(reauthKey)) {
                                    // Extension re-synced! needsReauth was cleared by /sync-cookies
                                    reauthSucceeded = true;
                                    break;
                                }
                            }

                            if (reauthSucceeded) {
                                logToFile(`[Jobs] ‚úÖ Fresh cookies received! Retrying job ${jobId}...`);
                                try {
                                    // Remove old broken client
                                    userClients.delete(reauthKey);
                                    const freshClient = await getClient(userToken);
                                    await freshClient.ensureBrowserReady();

                                    const imageUrl = await freshClient.generateInfographic(video_url);
                                    logToFile(`[Jobs] Job ${jobId} got image URL after re-auth: ${imageUrl}`);

                                    job.imageUrl = imageUrl;
                                    job.viewerUrl = `http://localhost:${HTTP_PORT}/view?url=${encodeURIComponent(imageUrl)}`;

                                    try {
                                        const imageBytes = await freshClient.downloadResource(imageUrl);
                                        const processedBuffer = await sharp(imageBytes, { failOnError: false })
                                            .resize({ width: 1024, withoutEnlargement: true })
                                            .jpeg({ quality: 85 })
                                            .toBuffer();
                                        job.imageData = processedBuffer.toString('base64');
                                        logToFile(`[Jobs] Image downloaded for ${jobId} after re-auth`);
                                    } catch (imgErr: any) {
                                        logToFile(`[Jobs] Image download failed for ${jobId}: ${imgErr.message}`);
                                    }

                                    job.status = 'completed';
                                    job.completedAt = Date.now();
                                    logToFile(`[Jobs] ‚úÖ Job ${jobId} completed after re-auth!`);
                                    return;
                                } catch (retryErr: any) {
                                    logToFile(`[Jobs] Retry after re-auth failed for ${jobId}: ${retryErr.message}`);
                                    job.status = 'failed';
                                    job.error = `Re-auth succeeded but retry failed: ${retryErr.message}`;
                                    job.completedAt = Date.now();
                                    return;
                                }
                            } else {
                                logToFile(`[Jobs] ‚è∞ Re-auth timeout for job ${jobId}. User did not re-sync cookies within 120s.`);
                                needsReauth.delete(reauthKey);
                                job.status = 'failed';
                                job.error = 'Session expired. Please re-sync your cookies using the Chrome extension, then try again.';
                                job.completedAt = Date.now();
                                return;
                            }
                        }
                        // Non-auth error: just fail normally
                        logToFile(`[Jobs] Job ${jobId} failed: ${e.message}`);
                        job.status = 'failed';
                        job.error = e.message;
                        job.completedAt = Date.now();
                    }
                })();
            }

            // Wait for completion (up to 10s)
            const MAX_WAIT = 10000; // 10 seconds (User requested fast feedback)
            const POLL_INTERVAL = 20000; // 20 seconds
            const startTime = Date.now();
            logToFile(`[Jobs] Waiting for job ${jobId} to complete (streaming mode)...`);

            while (Date.now() - startTime < MAX_WAIT) {
                if (job.status === 'completed') {
                    // Completed! Return with image for MCP App viewer
                    logToFile(`[Jobs] Returning completed job ${jobId} immediately.`);

                    const responseContent: any[] = [{
                        type: "text" as const,
                        text: `‚úÖ **Infographic Ready!**\n\nüñºÔ∏è **[Open in Viewer](${job.viewerUrl})**\n\nüì∏ **[Direct Image](${job.imageUrl})**\n\n‚è±Ô∏è Completed in ${Math.round((job.completedAt! - job.createdAt) / 1000)}s`
                    }];

                    // Add embedded image
                    if (job.imageData) {
                        responseContent.push({
                            type: "image" as const,
                            data: job.imageData,
                            mimeType: "image/jpeg"
                        });
                    }
                    return { content: responseContent };
                }

                if (job.status === 'failed') {
                    return { content: [{ type: "text" as const, text: `‚ùå Job failed: ${job.error}` }], isError: true };
                }

                await new Promise(resolve => setTimeout(resolve, POLL_INTERVAL));
            }

            // Timeout Fallback
            return {
                content: [{
                    type: "text" as const,
                    text: `üöÄ **Generation Started!**\n\nüìã **Job ID:** \`${jobId}\`\n\nThe job is running in the background. I'll check the status automatically until it's done...`
                }]
            };
        },
    );

    // --- Tool: check_infographic_status (MCP App Enabled for image display) ---
    logToFile("Registering tool: check_infographic_status");
    registerAppTool(
        server,
        "check_infographic_status",
        {
            title: "Check Infographic Status",
            description: "Check the status of an infographic generation job. When complete, displays the image in the viewer.",
            inputSchema: z.object({
                job_id: z.string().describe("The job ID returned by generate_infographic"),
                user_token: z.string().optional().describe("Optional user token for multi-user mode.")
            }) as any,
            _meta: { ui: { resourceUri } },
        },
        async (args: any) => {
            const job_id = args.job_id;
            const userToken = args.user_token;
            logToFile(`[Jobs] Checking status for job: ${job_id} (user: ${userToken || 'legacy'})`);

            const job = infographicJobs.get(job_id);
            if (!job) {
                return { content: [{ type: "text" as const, text: `‚ùå Job not found: ${job_id}. Jobs expire after 10 minutes.` }], isError: true };
            }

            if (job.status === 'pending' || job.status === 'processing') {
                const elapsed = Math.round((Date.now() - job.createdAt) / 1000);
                return {
                    content: [{
                        type: "text" as const,
                        text: `‚è≥ **Job Status: ${job.status.toUpperCase()}**\n\nüìã Job ID: \`${job_id}\`\nüé¨ Video: ${job.videoUrl}\n‚è±Ô∏è Elapsed: ${elapsed}s\n\n*Check again in 15-30 seconds...*`
                    }]
                };
            }

            if (job.status === 'failed') {
                return { content: [{ type: "text" as const, text: `‚ùå Job failed: ${job.error}` }], isError: true };
            }

            // Completed! Return with image for MCP App viewer
            logToFile(`[Jobs] Returning completed job ${job_id}, hasImageData: ${!!job.imageData}, imageDataLength: ${job.imageData?.length || 0}`);

            const responseContent: any[] = [{
                type: "text" as const,
                text: `‚úÖ **Infographic Ready!**\n\nüñºÔ∏è **[Open in Viewer](${job.viewerUrl})**\n\nüì∏ **[Direct Image](${job.imageUrl})**\n\n‚è±Ô∏è Completed in ${Math.round((job.completedAt! - job.createdAt) / 1000)}s`
            }];

            // Add embedded image for MCP App viewer
            if (job.imageData) {
                responseContent.push({
                    type: "image" as const,
                    data: job.imageData,
                    mimeType: "image/jpeg"
                });
            }

            return { content: responseContent };
        }
    );

    logToFile("All tools registered.");
}

// --- HTTP Server Setup ---
function startHttpServer(server: McpServer) {
    const expressApp = express();

    // Middleware
    expressApp.use((req, res, next) => {
        logToFile(`[HTTP] ${req.method} ${req.url} - Headers: ${JSON.stringify(req.headers)}`);
        next();
    });

    expressApp.use(cors({
        origin: '*',
        methods: ['GET', 'POST', 'OPTIONS'],
        allowedHeaders: ['Content-Type', 'Accept', 'Authorization'],
    }));
    expressApp.use(express.json({ limit: '10mb' }));

    // --- User Registration Endpoint ---
    expressApp.get("/register", (req, res) => {
        const token = generateUserToken();
        logToFile(`[Register] Generated new user token: ${token}`);
        res.json({
            success: true,
            user_token: token,
            instructions: "Copy this token into your Chrome extension settings, then sync your cookies."
        });
    });

    // Serve a simple registration page
    expressApp.get("/register.html", (req, res) => {
        res.send(`
<!DOCTYPE html>
<html>
<head>
    <title>NotebookLM MCP - User Registration</title>
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; max-width: 600px; margin: 50px auto; padding: 20px; background: #1a1a2e; color: #eee; }
        h1 { color: #00d4ff; }
        .token-box { background: #16213e; padding: 20px; border-radius: 10px; margin: 20px 0; font-family: monospace; font-size: 18px; word-break: break-all; }
        button { background: #00d4ff; color: #1a1a2e; border: none; padding: 12px 24px; font-size: 16px; cursor: pointer; border-radius: 5px; margin: 10px 5px 10px 0; }
        button:hover { background: #00b4dd; }
        .instructions { background: #16213e; padding: 15px; border-radius: 10px; margin-top: 20px; }
        .instructions ol { padding-left: 20px; }
        .instructions li { margin: 10px 0; }
    </style>
</head>
<body>
    <h1>üîê NotebookLM MCP Registration</h1>
    <p>Generate a unique token to link your Google account with this server.</p>
    <button onclick="generateToken()">Generate New Token</button>
    <div id="tokenDisplay" class="token-box" style="display:none;">
        <strong>Your Token:</strong><br><br>
        <span id="token"></span>
        <br><br>
        <button onclick="copyToken()">üìã Copy Token</button>
    </div>
    <div class="instructions">
        <h3>üìã Instructions</h3>
        <ol>
            <li>Click "Generate New Token" above</li>
            <li>Copy the token</li>
            <li>Open the NotebookLM Extension popup in Chrome</li>
            <li>Paste your token in the "User Token" field</li>
            <li>Click "Sync Cookies"</li>
            <li>When using ChatGPT, include your token: <em>"Summarize [URL] with token YOUR_TOKEN"</em></li>
        </ol>
    </div>
    <script>
        async function generateToken() {
            const res = await fetch('/register');
            const data = await res.json();
            document.getElementById('token').textContent = data.user_token;
            document.getElementById('tokenDisplay').style.display = 'block';
        }
        function copyToken() {
            navigator.clipboard.writeText(document.getElementById('token').textContent);
            alert('Token copied!');
        }
    </script>
</body>
</html>
        `);
    });

    // --- Cookie Sync Endpoint (from Chrome Extension) ---
    expressApp.post("/sync-cookies", (req, res) => {
        try {
            const { cookies, user_token } = req.body;
            const user_agent = req.get('User-Agent');
            if (!Array.isArray(cookies)) {
                res.status(400).json({ error: "Invalid cookies format" });
                return;
            }
            setCookiesFromExtension(cookies, user_token, user_agent);

            // Clear re-auth flag (fresh cookies received!)
            const reauthKey = user_token || '__legacy__';
            if (needsReauth.get(reauthKey)) {
                needsReauth.set(reauthKey, false);
                userClients.delete(reauthKey); // Force fresh client on next request
                logToFile(`[Cookies] ‚úÖ Re-auth flag cleared for ${reauthKey}. Fresh cookies received.`);
            }

            res.json({
                success: true,
                count: cookies.length,
                user_token: user_token || null,
                mode: user_token ? 'per-user' : 'legacy'
            });
        } catch (e: any) {
            logToFile(`[Cookies] Error processing cookies: ${e.message}`);
            res.status(500).json({ error: e.message });
        }
    });

    // --- Auth Events SSE Endpoint (extension connects once, server pushes when re-auth needed) ---
    expressApp.get("/auth-events", (req, res) => {
        const userToken = (req.query.user_token as string) || '__legacy__';

        // Set up SSE headers
        res.writeHead(200, {
            'Content-Type': 'text/event-stream',
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            'Access-Control-Allow-Origin': '*'
        });
        res.write(`data: ${JSON.stringify({ type: 'connected', user_token: userToken })}\n\n`);

        // Register this client
        if (!reauthSseClients.has(userToken)) {
            reauthSseClients.set(userToken, new Set());
        }
        reauthSseClients.get(userToken)!.add(res);
        logToFile(`[SSE] Extension connected for ${userToken}. Total clients: ${reauthSseClients.get(userToken)!.size}`);

        // Cleanup on disconnect
        req.on('close', () => {
            reauthSseClients.get(userToken)?.delete(res);
            logToFile(`[SSE] Extension disconnected for ${userToken}.`);
        });

        // Keep-alive ping every 30s
        const keepAlive = setInterval(() => {
            try { res.write(': keepalive\n\n'); } catch (e) { clearInterval(keepAlive); }
        }, 30000);
        req.on('close', () => clearInterval(keepAlive));
    });

    // Store transports by session ID (supports both SSE and Streamable HTTP)
    const sessionTransports = new Map<string, SSEServerTransport | StreamableHTTPServerTransport>();

    // SSE Connection Endpoint
    // Clients connect here (GET) to start the session.
    // We support both /sse (standard) and /mcp (what user tried)
    const handleSseConnection = async (req: express.Request, res: express.Response) => {
        logToFile(`[HTTP] New SSE connection request: ${req.path}`);
        req.socket.setTimeout(0); // Disable socket timeout for SSE connection

        // Prevent buffering and caching at all layers (Cloudflare, Nginx, Browser)
        res.setHeader("Content-Type", "text/event-stream");
        res.setHeader("Cache-Control", "no-cache, no-transform");
        res.setHeader("Connection", "keep-alive");
        res.setHeader("X-Accel-Buffering", "no");
        res.setHeader("Content-Encoding", "none");

        // The client needs to know where to send messages (POST).
        // We tell it to send to /messages.
        const transport = new SSEServerTransport("/messages", res);

        logToFile(`[HTTP] Created transport with sessionId: ${transport.sessionId}`);
        sessionTransports.set(transport.sessionId, transport);

        // Heartbeat to keep connection alive (prevent Cloudflare/Proxy timeout)
        const heartbeatInterval = setInterval(() => {
            if (res.writableEnded) {
                clearInterval(heartbeatInterval);
                return;
            }
            res.write(": keepalive\n\n");
            logToFile(`[HTTP] Sent heartbeat for session: ${transport.sessionId}`);
        }, 15000); // 15 seconds

        transport.onclose = () => {
            logToFile(`[HTTP] SSE connection closed: ${transport.sessionId}`);
            clearInterval(heartbeatInterval);
            sessionTransports.delete(transport.sessionId);
        };

        (transport as any).onerror = (error: any) => {
            logToFile(`[HTTP] SSE Transport Error (session: ${transport.sessionId}): ${error?.message || String(error)}`);
        };

        req.on("close", () => {
            logToFile(`[HTTP] Express Request 'close' event (Client disconnected?) for session: ${transport.sessionId}`);
        });

        req.on("error", (err) => {
            logToFile(`[HTTP] Express Request 'error' event: ${err.message}`);
        });

        try {
            await server.connect(transport);
            logToFile(`[HTTP] server.connect() completed for session: ${transport.sessionId}`);
        } catch (error) {
            logToFile(`[HTTP] Error processing SSE connection: ${error}`);
        }
    };

    expressApp.get("/sse", handleSseConnection);

    //=========================================================================
    // STREAMABLE HTTP TRANSPORT (Protocol Version 2025-06-18)
    // ChatGPT Connectors prefer this newer transport.
    //=========================================================================
    expressApp.all("/mcp", async (req, res) => {
        logToFile(`[HTTP] ${req.method} /mcp received`);

        try {
            // Check for existing session ID
            const sessionId = req.headers['mcp-session-id'] as string | undefined;
            let transport: StreamableHTTPServerTransport | undefined;

            if (sessionId && sessionTransports.has(sessionId)) {
                const existingTransport = sessionTransports.get(sessionId);
                if (existingTransport instanceof StreamableHTTPServerTransport) {
                    transport = existingTransport;
                } else {
                    // Session exists but uses a different transport protocol (SSE)
                    res.status(400).json({
                        jsonrpc: '2.0',
                        error: { code: -32000, message: 'Session uses a different transport protocol' },
                        id: null
                    });
                    return;
                }
            } else if (!sessionId && req.method === 'POST' && isInitializeRequest(req.body)) {
                // New session initialization
                logToFile(`[HTTP] Initializing new Streamable HTTP session...`);
                transport = new StreamableHTTPServerTransport({
                    sessionIdGenerator: () => crypto.randomUUID(),
                    onsessioninitialized: (newSessionId) => {
                        logToFile(`[HTTP] Streamable HTTP session initialized: ${newSessionId}`);
                        sessionTransports.set(newSessionId, transport!);
                    }
                });

                transport.onclose = () => {
                    const sid = transport!.sessionId;
                    if (sid && sessionTransports.has(sid)) {
                        logToFile(`[HTTP] Streamable HTTP session closed: ${sid}`);
                        sessionTransports.delete(sid);
                    }
                };

                // Connect to MCP server
                await server.connect(transport);
            } else if (!sessionId) {
                // No session and not an initialize request
                res.status(400).json({
                    jsonrpc: '2.0',
                    error: { code: -32000, message: 'Missing session ID or not an initialize request' },
                    id: null
                });
                return;
            }

            if (!transport) {
                res.status(404).json({
                    jsonrpc: '2.0',
                    error: { code: -32000, message: 'Session not found' },
                    id: null
                });
                return;
            }

            // Handle the request using Streamable HTTP transport
            await transport.handleRequest(req, res, req.body);
        } catch (error) {
            logToFile(`[HTTP] Error handling /mcp: ${error}`);
            if (!res.headersSent) {
                res.status(500).json({
                    jsonrpc: '2.0',
                    error: { code: -32603, message: 'Internal server error' },
                    id: null
                });
            }
        }
    });

    //=========================================================================
    // DEPRECATED HTTP+SSE TRANSPORT (Protocol Version 2024-11-05)
    // POST /messages endpoint for backwards compatibility
    //=========================================================================
    expressApp.post("/messages", async (req, res) => {
        const sessionId = req.query.sessionId as string;
        logToFile(`[HTTP] POST /messages (session: ${sessionId})`);

        const transport = sessionTransports.get(sessionId);
        if (!transport || !(transport instanceof SSEServerTransport)) {
            logToFile(`[HTTP] Session not found or wrong type: ${sessionId}`);
            res.status(404).send("Session not found");
            return;
        }

        // Pass req.body to fix known SDK parsing issue
        await transport.handlePostMessage(req, res, req.body);
    });

    // Serve static files from public directory (go up 2 levels from dist/src/)
    const publicPath = path.resolve(__dirname, '../../public');
    expressApp.use('/public', express.static(publicPath));

    // Infographic Viewer endpoint - redirect to static HTML
    expressApp.get("/view", (req, res) => {
        const imageUrl = req.query.url as string;
        if (!imageUrl) {
            res.status(400).send("Missing 'url' query parameter");
            return;
        }

        logToFile(`[HTTP] Serving infographic view for: ${imageUrl.substring(0, 50)}...`);

        // Serve the HTML file
        const htmlPath = path.join(publicPath, 'infographic-viewer.html');
        logToFile(`[HTTP] Serving file from: ${htmlPath}`);
        res.sendFile(htmlPath);
    });

    // Health check endpoint
    expressApp.get("/health", (_req, res) => {
        res.json({ status: "ok", mode: "http", port: HTTP_PORT });
    });

    // Dedicated SSE endpoint
    expressApp.get("/sse", async (req, res) => {
        logToFile(`[HTTP] GET /sse request -> Handling as SSE`);
        await handleSseConnection(req, res);
    });

    // Root info endpoint (Supports SSE auto-discovery)
    expressApp.get("/", async (req, res) => {
        const accept = req.headers.accept || "";
        if (accept.includes("text/event-stream")) {
            logToFile(`[HTTP] Root request with Accept: text/event-stream -> Handling as SSE`);
            await handleSseConnection(req, res);
            return;
        }

        res.json({
            name: "NotebookLM MCP Server",
            version: "1.0.0",
            endpoints: {
                mcp: "POST /mcp",
                view: "GET /view?url=<image_url>",
                health: "GET /health",
            },
            instructions: "Use cloudflared to create a tunnel: npx cloudflared tunnel --url http://localhost:" + HTTP_PORT,
        });
    });

    const httpServer = expressApp.listen(HTTP_PORT, () => {
        logToFile(`HTTP/WS Server listening on port ${HTTP_PORT}`);
    });

    httpServer.on('error', (e: any) => {
        if (e.code === 'EADDRINUSE') {
            logToFile(`Port ${HTTP_PORT} is in use. Assuming background server is running. Continuing in Stdio/Transport mode.`);
        } else {
            logToFile(`HTTP Server Error: ${e}`);
        }
    });
}

// --- Stdio Server Setup ---
async function startStdioServer(server: McpServer) {
    // In stdio mode, redirect console.log to stderr to keep stdout clean for MCP
    console.log = console.error;

    const transport = new StdioServerTransport();
    await server.connect(transport);
    logToFile("NotebookLM MCP Server running on Stdio");
}

// --- Main Entry Point ---
async function main() {
    const useStdio = process.argv.includes("--stdio");
    if (useStdio) {
        console.log = console.error;
    }

    logToFile("SERVER STARTING...");
    logToFile("Initializing Transports...");



    const server = new McpServer({
        name: "NotebookLM",
        version: "1.0.0",
    });

    registerTools(server);

    // Always start HTTP server (provides dual support and serves UI assets)
    startHttpServer(server);

    if (useStdio) {
        await startStdioServer(server);
    }
}

main().catch((e) => {
    logToFile(`FATAL ERROR: ${e}`);
    console.error(`FATAL ERROR: ${e}`);
    process.exit(1);
});
